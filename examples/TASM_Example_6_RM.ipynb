{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XD1A1QFf3AE8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "N-HmtohewKhR",
        "outputId": "8865c095-62c8-4c1e-8f38-b7b08edc3919"
      },
      "outputs": [],
      "source": [
        "#%pip install -U albumentations>=3.0.0\n",
        "#!git clone https://github.com/JanMarcelKezmann/TensorFlow-Advanced-Segmentation-Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "19G-H4yhw1Vo",
        "outputId": "b0889b9b-77d9-44ba-8c11-7355dac5f3b1"
      },
      "outputs": [],
      "source": [
        "%cd semanctic-segmentation-tasm\n",
        "import tensorflow_advanced_segmentation_models as tasm\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgGJsTMmxzZN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MbbfgJOt28dw"
      },
      "source": [
        "## Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UuVoORrpnIP"
      },
      "outputs": [],
      "source": [
        "# Data Handling\n",
        "DATA_DIR = r\"D:\\Datasets\\CeyMo\"\n",
        "\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train/images')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train/mask_annotations')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'test/images')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'train/mask_annotations')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test/images')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'train/mask_annotations')\n",
        "\n",
        "print(os.path.exists(x_train_dir))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(list):\n",
        "    return [item for sublist in list for item in sublist]\n",
        "\n",
        "def get_folders_in_folder(folder):\n",
        "    return [f[0] for f in os.walk(folder)][1:]\n",
        "\n",
        "def get_files_in_folder(folder, pattern=None):\n",
        "    if pattern is None:\n",
        "        return sorted([os.path.join(folder, f) for f in os.listdir(folder)])\n",
        "    else:\n",
        "        return sorted([os.path.join(folder, f) for f in os.listdir(folder) if pattern in f])\n",
        "\n",
        "def get_files_recursive(folder, pattern=None):\n",
        "    if not bool(get_folders_in_folder(folder)):\n",
        "        return get_files_in_folder(folder, pattern)\n",
        "    else:\n",
        "        return flatten([get_files_in_folder(f, pattern) for f in get_folders_in_folder(folder)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DOLbeHZpq7l"
      },
      "outputs": [],
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "# helper function for data visualization    \n",
        "def denormalize(x):\n",
        "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)    \n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x\n",
        "    \n",
        "def round_clip_0_1(x, **kwargs):\n",
        "    return x.round().clip(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_files_recursive(x_train_dir)[:2], get_files_recursive(y_train_dir)[:2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Label classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "# a label and all meta information\n",
        "Label = namedtuple( 'Label' , [\n",
        "\n",
        "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
        "                    # We use them to uniquely name a class\n",
        "\n",
        "    'id'          , # An integer ID that is associated with this label.\n",
        "                    # The IDs are used to represent the label in ground truth images\n",
        "                    # An ID of -1 means that this label does not have an ID and thus\n",
        "                    # is ignored when creating ground truth images (e.g. license plate).\n",
        "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
        "                    # evaluation server.\n",
        "\n",
        "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
        "                    # ground truth images with train IDs, using the tools provided in the\n",
        "                    # 'preparation' folder. However, make sure to validate or submit results\n",
        "                    # to our evaluation server using the regular IDs above!\n",
        "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
        "                    # are mapped to the same class in the ground truth images. For the inverse\n",
        "                    # mapping, we use the label that is defined first in the list below.\n",
        "                    # For example, mapping all void-type classes to the same ID in training,\n",
        "                    # might make sense for some approaches.\n",
        "                    # Max value is 255!\n",
        "\n",
        "    'category'    , # The name of the category that this label belongs to\n",
        "\n",
        "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
        "                    # on category level.\n",
        "\n",
        "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
        "\n",
        "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
        "                    # during evaluations or not\n",
        "\n",
        "    'color'       , # The color of this label\n",
        "    ] )\n",
        "\n",
        "labels = [\n",
        "    #       name                      id    trainId   category  catId    hasInstances   ignoreInEval        color\n",
        "    Label(  'unlabeled'             ,  0 ,        0 , 'void'    , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'bus lane'              ,  1 ,        1 , 'void'    , 0       , False        , True         , (  0,255,255) ),\n",
        "    Label(  'cycle lane'            ,  2 ,        2 , 'void'    , 0       , False        , True         , (  0,128,255) ),\n",
        "    Label(  'diamond'               ,  3 ,        3 , 'void'    , 0       , False        , True         , (178,102,255) ),\n",
        "    Label(  'junction box'          ,  4 ,        4 , 'void'    , 0       , False        , True         , (255,255, 51) ),\n",
        "    Label(  'left arrow'            ,  5 ,        5 , 'void'    , 0       , False        , True         , (255,102,178) ),\n",
        "    Label(  'pedestrian crossing'   ,  6 ,        6 , 'void'    , 0       , False        , True         , (255,255,  0) ),\n",
        "    Label(  'right arrow'           ,  7 ,        7 , 'flat'    , 1       , False        , False        , (255,  0,127) ),\n",
        "    Label(  'straight arrow'        ,  8 ,        8 , 'flat'    , 1       , False        , False        , (255,  0,255) ),\n",
        "    Label(  'slow'                  ,  9 ,        9 , 'flat'    , 1       , False        , True         , (  0,255,  0) ),\n",
        "    Label(  'straight-left arrow'   , 10 ,       10 , 'flat'    , 1       , False        , True         , (255,128,  0) ),\n",
        "    Label(  'straight-right arrow'  , 11 ,       11 , 'flat'    , 1       , False        , True         , (255,  0,  0) )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_color = [list(labels[k].color) for k in range(len(labels)) if labels[k].trainId >= 0 and labels[k].trainId < 255]\n",
        "labels_name = [labels[k].name for k in range(len(labels)) if labels[k].trainId >= 0 and labels[k].trainId < 255]\n",
        "\n",
        "print(\"Number of classes - \", len(labels_color))\n",
        "print(\"\\n\")\n",
        "for name, color in zip(labels_name, labels_color):\n",
        "    print(f\"{name} - {color}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define some Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOTAL_CLASSES = labels_name\n",
        "N_CLASSES = len(labels_color)\n",
        "BATCH_SIZE = 2\n",
        "HEIGHT = 256\n",
        "WIDTH = 256\n",
        "BACKBONE_NAME = \"efficientnetb3\"\n",
        "WEIGHTS = \"imagenet\"\n",
        "WWO_AUG = True # train data with and without augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_shuffle = True\n",
        "val_shuffle = True\n",
        "seed = 29598"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Augmentation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define heavy augmentations\n",
        "def get_training_augmentation(height, width):\n",
        "    train_transform = [\n",
        "        A.HorizontalFlip(p=0.3),\n",
        "\n",
        "        # A.ShiftScaleRotate(scale_limit=0.6, rotate_limit=0.2, shift_limit=0.1, p=1, border_mode=0),\n",
        "\n",
        "        A.PadIfNeeded(min_height=height, min_width=width, always_apply=True, border_mode=0),\n",
        "        # A.RandomCrop(height=height, width=width, always_apply=True),\n",
        "        A.Resize(height, width, always_apply=True),\n",
        "\n",
        "        # A.GaussNoise(p=0.2),\n",
        "        # A.Perspective(p=0.5),\n",
        "\n",
        "        # A.OneOf(\n",
        "        #     [\n",
        "        #         A.CLAHE(p=1),\n",
        "        #         A.RandomBrightnessContrast(p=1),\n",
        "        #         A.RandomGamma(p=1),\n",
        "        #     ],\n",
        "        #     p=0.9,\n",
        "        # ),\n",
        "\n",
        "        # A.OneOf(\n",
        "        #     [\n",
        "        #         A.Sharpen(p=1),\n",
        "        #         A.Blur(blur_limit=3, p=1),\n",
        "        #         A.MotionBlur(blur_limit=3, p=1),\n",
        "        #     ],\n",
        "        #     p=0.9,\n",
        "        # ),\n",
        "\n",
        "        # A.OneOf(\n",
        "        #     [\n",
        "        #         A.RandomContrast(p=1),\n",
        "        #         A.HueSaturationValue(p=1),\n",
        "        #     ],\n",
        "        #     p=0.9,\n",
        "        # ),\n",
        "        # A.Lambda(mask=round_clip_0_1)\n",
        "    ]\n",
        "    return A.Compose(train_transform)\n",
        "\n",
        "def get_validation_augmentation(height, width):\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        A.PadIfNeeded(height, width),\n",
        "        A.Resize(height, width, always_apply=True)\n",
        "    ]\n",
        "    return A.Compose(test_transform)\n",
        "\n",
        "def data_get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nNdSxUGk2pFi"
      },
      "source": [
        "## Data Generation Functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_image_label_path_generator(images_dir, masks_dir, shuffle=False, seed=None):\n",
        "    # ids = sorted(os.listdir(images_dir))\n",
        "    # mask_ids = sorted(os.listdir(masks_dir))\n",
        "    ids = get_files_recursive(images_dir)\n",
        "    mask_ids = get_files_recursive(masks_dir)\n",
        "\n",
        "    if shuffle == True:\n",
        "        if seed is not None:\n",
        "            tf.random.set_seed(seed)\n",
        "\n",
        "        indices = tf.range(start=0, limit=tf.shape(ids)[0], dtype=tf.int32)\n",
        "        shuffled_indices = tf.random.shuffle(indices)\n",
        "\n",
        "        ids = tf.gather(ids, shuffled_indices).numpy().astype(str)\n",
        "        mask_ids = tf.gather(mask_ids, shuffled_indices).numpy().astype(str)\n",
        "\n",
        "    images_fps = [os.path.join(images_dir, image_id) for image_id in ids]\n",
        "    masks_fps = [os.path.join(masks_dir, image_id) for image_id in mask_ids]\n",
        "\n",
        "    while True:\n",
        "        for i in range(len(images_fps)):\n",
        "            yield [images_fps[i], masks_fps[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def label_segmentation_mask(seg, class_labels):\n",
        "    \"\"\"\n",
        "    Given a 3D (W, H, depth=3) segmentation mask, prepare a 2D labeled segmentation mask\n",
        "    # Arguments\n",
        "        seg: The segmentation mask where each cell of depth provides the r, g, and b values\n",
        "        class_labels\n",
        "    # Returns\n",
        "        Labeled segmentation mask where each cell provides its label value\n",
        "    \"\"\"\n",
        "    seg = seg.astype(\"uint8\")\n",
        "\n",
        "    # returns a 2D matrix of size W x H of the segmentation mask\n",
        "    label = np.zeros(seg.shape[:2], dtype=np.uint8)\n",
        "\n",
        "    for i, rgb in enumerate(class_labels):\n",
        "        label[(seg == rgb).all(axis=2)] = i\n",
        "    return label\n",
        "\n",
        "def one_hot_encode(seg, class_labels):\n",
        "    \"\"\"\n",
        "    Convert a segmentation mask label array to one-hot format\n",
        "    by replacing each pixel value with a vector of length num_classes\n",
        "    # Arguments\n",
        "        seg: The 3D array segmentation mask\n",
        "        class_labels\n",
        "    # Returns\n",
        "        A 3D array with the same width and height as the input, but\n",
        "        with a depth size of num_classes\n",
        "    \"\"\"\n",
        "    num_classes = len(class_labels)  # seg dim = H*W*3\n",
        "    label = label_segmentation_mask(seg, class_labels)  # label dim = H*W\n",
        "    one_hot = to_categorical(label, num_classes)  # one_hot dim = H*W*N\n",
        "    return one_hot\n",
        "\n",
        "def decode_one_hot(label_one_hot, labels_name):\n",
        "    pred = np.argmax(label_one_hot, axis=-1)\n",
        "    color_codes = np.array(labels_name)\n",
        "    pred = color_codes[pred.astype(np.uint8)]\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image_label(images_paths, masks_paths, class_labels, augmentation=None):\n",
        "    # read data\n",
        "    image = cv2.imread(images_paths)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    mask = cv2.imread(masks_paths)\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # apply augmentations\n",
        "    if augmentation:\n",
        "        sample = augmentation(image=image, mask=mask)\n",
        "        image, mask = sample['image'], sample['mask']\n",
        "    \n",
        "    mask_one_hot = one_hot_encode(mask, class_labels)\n",
        "    return image, mask, mask_one_hot"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_label_path_generator = create_image_label_path_generator(x_train_dir, y_train_dir, shuffle=True, seed=None)\n",
        "image_path, label_path = next(image_label_path_generator)\n",
        "\n",
        "print(image_path, label_path)\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "mask = cv2.imread(label_path)\n",
        "image_aug, label_aug, label_one_hot = process_image_label(image_path, label_path, labels_color, augmentation=get_training_augmentation(height=HEIGHT, width=WIDTH))\n",
        "\n",
        "print(image.shape, mask.shape, image_aug.shape, label_aug.shape, label_one_hot.shape)\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.imshow(image)\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.imshow(mask)\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.imshow(image_aug)\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.imshow(label_aug)\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.imshow(decode_one_hot(label_one_hot, labels_color))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c6I5PVByJD1"
      },
      "outputs": [],
      "source": [
        "################################################################################################\n",
        "# Data Generator\n",
        "################################################################################################\n",
        "def DataGenerator(train_dir, label_dir, batch_size, height, width, class_labels, augmentation, wwo_aug=False, shuffle=False, seed=None):\n",
        "    image_label_path_generator = create_image_label_path_generator(\n",
        "        train_dir, label_dir, shuffle=shuffle, seed=seed\n",
        "    )\n",
        "    if wwo_aug:\n",
        "        while True:\n",
        "            images = np.zeros(shape=[batch_size, height, width, 3])\n",
        "            labels = np.zeros(shape=[batch_size, height, width, len(class_labels)], dtype=np.float32)\n",
        "            for i in range(0, batch_size, 2):\n",
        "                image_path, label_path = next(image_label_path_generator)\n",
        "                image_aug, label_aug, label_aug_oh = process_image_label(image_path, label_path, class_labels, augmentation=augmentation)\n",
        "                image_wo_aug, label_wo_aug, label_wo_aug_oh = process_image_label(image_path, label_path, class_labels, \n",
        "                                                                                  augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH))\n",
        "                images[i], labels[i] = image_aug, label_aug_oh\n",
        "                images[i + 1], labels[i + 1] = image_wo_aug, label_wo_aug_oh\n",
        "\n",
        "            yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)\n",
        "    else:\n",
        "        while True:\n",
        "            images = np.zeros(shape=[batch_size, height, width, 3])\n",
        "            labels = np.zeros(shape=[batch_size, height, width, len(class_labels)], dtype=np.float32)\n",
        "            for i in range(batch_size):\n",
        "                image_path, label_path = next(image_label_path_generator)\n",
        "                image, label, label_oh = process_image_label(image_path, label_path, class_labels, augmentation=augmentation)\n",
        "                images[i], labels[i] = image, label_oh\n",
        "\n",
        "            yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the Data\n",
        "\n",
        "<p>There are three options for the training dataset: </p>\n",
        "\n",
        "- Training without augmentation\n",
        "- Training with augmentation\n",
        "- Training with and without augmentation (twice the data)\n",
        "\n",
        "<p>Validation and Test data are of course without augmentation</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##########################################################################################################\n",
        "# Data Generator\n",
        "#           augmentation - wwo_aug\n",
        "# get_train_augmentation -  true    -   both (training) and (validation) augmentation   - TrainSetwwoAug\n",
        "# get_train_augmentation -  false   -   only (training) augmentation                    - TrainSet\n",
        "# get_valid_augmentation -  true    -   both (validation) and (validation) augmentation - xx\n",
        "# get_valid_augmentation -  false   -   only (validation) augmentation                  - TrainSetwoAug, ValidationSet, TestSet\n",
        "##########################################################################################################\n",
        "TrainSet = DataGenerator(\n",
        "    x_train_dir,\n",
        "    y_train_dir,\n",
        "    BATCH_SIZE,\n",
        "    HEIGHT,\n",
        "    WIDTH,\n",
        "    labels_color,\n",
        "    augmentation=get_training_augmentation(height=HEIGHT, width=WIDTH),\n",
        "    shuffle=train_shuffle,\n",
        "    seed=seed\n",
        "    )\n",
        "\n",
        "TrainSetwoAug = DataGenerator(\n",
        "    x_train_dir,\n",
        "    y_train_dir,\n",
        "    BATCH_SIZE,\n",
        "    HEIGHT,\n",
        "    WIDTH,\n",
        "    labels_color,\n",
        "    augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH),\n",
        "    shuffle=train_shuffle,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "TrainSetwwoAug = DataGenerator(\n",
        "    x_train_dir,\n",
        "    y_train_dir,\n",
        "    BATCH_SIZE,\n",
        "    HEIGHT,\n",
        "    WIDTH,\n",
        "    labels_color,\n",
        "    augmentation=get_training_augmentation(height=HEIGHT, width=WIDTH),\n",
        "    wwo_aug=True,\n",
        "    shuffle=train_shuffle,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "ValidationSet = DataGenerator(\n",
        "    x_valid_dir,\n",
        "    y_valid_dir,\n",
        "    1,\n",
        "    HEIGHT,\n",
        "    WIDTH,\n",
        "    labels_color,\n",
        "    augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH),\n",
        "    shuffle=val_shuffle,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "TestSet = DataGenerator(\n",
        "    x_test_dir,\n",
        "    y_test_dir,\n",
        "    1,\n",
        "    HEIGHT,\n",
        "    WIDTH,\n",
        "    labels_color,\n",
        "    augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in TrainSet:\n",
        "    sample_image, sample_mask = i[0][0], i[1][0]\n",
        "    print(len(i))\n",
        "    print(i[0].shape)\n",
        "    print(i[1].shape)\n",
        "    \n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(i[0][0])\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(decode_one_hot(i[1][0], labels_color))\n",
        "    plt.show()    \n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_samples_train = len(get_files_recursive(x_train_dir))\n",
        "n_samples_valid = len(get_files_recursive(x_valid_dir))\n",
        "n_samples_test = len(get_files_recursive(x_test_dir))\n",
        "\n",
        "n_samples_train, n_samples_valid, n_samples_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_r07PE2e5T"
      },
      "source": [
        "## Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "vuXSFQKFyMJN",
        "outputId": "3938ba6a-bb9c-4026-d344-2f69efd69f49"
      },
      "outputs": [],
      "source": [
        "base_model, layers, layer_names = tasm.create_base_model(name=BACKBONE_NAME, weights=WEIGHTS, height=HEIGHT, width=WIDTH, include_top=False, pooling=None)\n",
        "\n",
        "BACKBONE_TRAINABLE = False\n",
        "model = tasm.DANet(n_classes=N_CLASSES, base_model=base_model, output_layers=layers, backbone_trainable=BACKBONE_TRAINABLE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g3b_BJTK2hH9"
      },
      "source": [
        "### Define the optimizer as well as losses, metrics and callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqpKIfvEy4PP"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate=0.2, momentum=0.9)\n",
        "metrics = [tasm.metrics.IOUScore(threshold=0.5)]\n",
        "categorical_focal_dice_loss = tasm.losses.CategoricalFocalLoss(alpha=0.25, gamma=2.0) + tasm.losses.DiceLoss()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=categorical_focal_dice_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "model.run_eagerly = False\n",
        "\n",
        "callbacks = [\n",
        "             tf.keras.callbacks.ModelCheckpoint(\"model.hdf5\", verbose=1, save_weights_only=True, save_best_only=True),\n",
        "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"iou_score\", factor=0.2, patience=6, verbose=1, mode=\"max\"),\n",
        "             tf.keras.callbacks.EarlyStopping(monitor=\"iou_score\", patience=16, mode=\"max\", verbose=1, restore_best_weights=True)\n",
        "]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Short check if model works properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "kVDXqEda4M0Y",
        "outputId": "ae4156a1-65f9-4929-9498-64970dc057eb"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=1):\n",
        "    output_model = model(sample_image[tf.newaxis, ...])\n",
        "    print(output_model.shape)\n",
        "    \n",
        "    output_mask = create_mask(output_model)\n",
        "    print(output_mask.shape)\n",
        "\n",
        "    scce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    print(\"SparseCategoricalCrossentroy: \" + str(scce(sample_mask, output_model[0]).numpy()))\n",
        "    print(\"Iou-Score: \" + str(tasm.losses.iou_score(sample_mask, output_model[0]).numpy()))\n",
        "    print(\"categorical Focal Dice Loss: \" + str(categorical_focal_dice_loss(sample_mask, output_model[0]).numpy()))\n",
        "\n",
        "    display([sample_image, K.one_hot(K.squeeze(output_mask, axis=-1), 3)])\n",
        "    \n",
        "show_predictions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RuKsvaXroPB"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FVa0a9ParqlC"
      },
      "source": [
        "#### Training Procedure\n",
        "##### 1) Train model with freezed backbone only on train data\n",
        "##### 2) Train completely unfreezed model with train and validation data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vQcuZ0uks1Eg"
      },
      "source": [
        "### 1) Train model with freezed backbone only on train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ps2MqDl0rnwH",
        "outputId": "75d60453-cb09-43d2-bfbb-5bea6bbb684a"
      },
      "outputs": [],
      "source": [
        "## Set Backbone trainable to False\n",
        "for layer in model.layers:\n",
        "    if \"model\" in layer.name:\n",
        "        layer.trainable = False\n",
        "\n",
        "    print(layer.name + \": \" + str(layer.trainable))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b7aK4dbE4Q5R",
        "outputId": "6d0e0bb4-5ff5-4e9b-a3c3-0217f68f18b7"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = np.floor(n_samples_train / BATCH_SIZE)\n",
        "\n",
        "print(BATCH_SIZE, steps_per_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    TrainSet,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=15,\n",
        "    callbacks=callbacks,\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pjLCU1t9yls6"
      },
      "source": [
        "#### Plot Training IoU Scores and Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "cQ8j-81o5T24",
        "outputId": "74032e62-e046-4878-9fa2-b1d20d3b3e40"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['iou_score'])\n",
        "# plt.plot(history.history['val_iou_score'])\n",
        "plt.title('Model IOU Score')\n",
        "plt.ylabel('IOU Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train completely unfreezed model with train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "QAVuJiLYrSIT",
        "outputId": "e95f5a44-a82a-4711-9916-4b6fc8a798aa"
      },
      "outputs": [],
      "source": [
        "# Make whole model trainable and use validation set\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "    print(layer.name + \": \" + str(layer.trainable))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1-bKBmB0gGT"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
        "metrics = [tasm.metrics.IOUScore(threshold=0.5)]\n",
        "categorical_focal_dice_loss = tasm.losses.CategoricalFocalLoss(alpha=0.25, gamma=2.0) + tasm.losses.DiceLoss()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=categorical_focal_dice_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "model.run_eagerly = True\n",
        "\n",
        "callbacks = [\n",
        "             tf.keras.callbacks.ModelCheckpoint(\"DeepLabV3plus.hdf5\", verbose=1, save_weights_only=True, save_best_only=True),\n",
        "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", factor=0.2, patience=6, verbose=1, mode=\"max\"),\n",
        "             tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=16, mode=\"max\", verbose=1, restore_best_weights=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WftWeRKNrR8T",
        "outputId": "307ab66a-2dd9-44cf-ee5d-32cf9118d95b"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    TrainSetwwoAug,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=30,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=ValidationSet,\n",
        "    validation_steps=len(os.listdir(x_valid_dir)),\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6b4Dpx7z2eO"
      },
      "source": [
        "#### Plot Training IoU Scores and Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "k4z4_GHErVeA",
        "outputId": "543c5ee4-c977-4d51-e8e3-918662ae97f9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['iou_score'])\n",
        "plt.plot(history.history['val_iou_score'])\n",
        "plt.title('Model IOU Score')\n",
        "plt.ylabel('IOU Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EYjXcNfLrWds"
      },
      "source": [
        "# Evaluation on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "PsPWoREF5WDn",
        "outputId": "b29ac434-d6fe-4b2c-a1eb-c0fc9bf7235c"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(TestSet, steps=101)\n",
        "\n",
        "print(\"Loss: {:.5}\".format(scores[0]))\n",
        "for metric, value in zip(metrics, scores[1:]):\n",
        "    if metric != \"accuracy\":\n",
        "        metric = metric.__name__\n",
        "    print(\"mean {}: {:.5}\".format(metric, value))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S-XxJyuxuIMx"
      },
      "source": [
        "## Visual Examples on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(decode_one_hot(model.predict(image)[0], labels_color))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.predict(image)[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pr_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yiJ9flDxD9wY",
        "outputId": "4336e6fb-55c7-4362-b398-3464773b2181"
      },
      "outputs": [],
      "source": [
        "n = 5\n",
        "ids = np.random.choice(np.arange(101), size=n,replace=False)\n",
        "print(ids)\n",
        "\n",
        "counter = 0\n",
        "second_counter = 0\n",
        "for i in TestSet:\n",
        "    if counter in ids:\n",
        "        image, gt_mask = i\n",
        "        # image = np.expand_dims(image, axis=0)\n",
        "        pr_mask = model.predict(image)\n",
        "        pr_mask = np.argmax(pr_mask, axis=-1)\n",
        "\n",
        "        print(counter)\n",
        "        \n",
        "        visualize(\n",
        "            image=denormalize(image.numpy().squeeze()),\n",
        "            gt_mask=gt_mask.numpy().squeeze(),\n",
        "            pr_mask=pr_mask.squeeze(),\n",
        "        )\n",
        "        second_counter += 1\n",
        "    counter += 1\n",
        "    if second_counter == n:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Yz25_UnEF3A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TASM Example 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
